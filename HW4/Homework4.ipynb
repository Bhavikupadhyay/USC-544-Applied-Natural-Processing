{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f250ef82",
   "metadata": {},
   "source": [
    "#### Name: Bhavik Kethan Upadhyay\n",
    "#### USC ID: 7750 8874 57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e5dcc",
   "metadata": {},
   "source": [
    "### Answers to Questions:\n",
    "\n",
    "#### Task 1:\n",
    "Hyperparameters used for creating and training BiLSTM without embeddings:\n",
    "\n",
    "* Model Architecture\n",
    "    - input_dim = torch.max(train_data1) + 1 (which gives 23589)\n",
    "    - embedding_dim = 100\n",
    "    - hidden_dim = 256\n",
    "    - dropout_prob=0.33\n",
    "    - linear_dim=128\n",
    "    - out_dim = 9\n",
    "    \n",
    "* Batch size = 32\n",
    "* Optimizer = AdamW\n",
    "* Learning rate = Default (1e-3)\n",
    "* Loss function = Cross Entropy\n",
    "* epochs = 20 (with early stopping)\n",
    "\n",
    "- Scores on Validation Set:\n",
    "    * F1: 79.986\n",
    "    * Recall: 77.078\n",
    "    * Precision: 83.121\n",
    "    \n",
    "- Scores on Test Set:\n",
    "    * F1: 70.546\n",
    "    * Recall: 66.643\n",
    "    * Precision: 74.935\n",
    "\n",
    "#### Task 2:\n",
    "Hyperparameters used for creating and training BiLSTM with GloVe embeddings:\n",
    "\n",
    "* Model Architecture\n",
    "    - embedding_dim = 100\n",
    "    - hidden_dim = 256\n",
    "    - dropout_prob=0.33\n",
    "    - linear_dim=128\n",
    "    - out_dim = 9\n",
    "* Epochs = 20 (with early stopping)\n",
    "* Batch size = 32\n",
    "* Optimizer = AdamW\n",
    "* Learning rate = Default (1e-3)\n",
    "* Loss function = Cross Entropy\n",
    "(Note: You don't have to specify input_dim here as you are using pretrained embeddings. \n",
    "\n",
    "- Scores on Validation Set:\n",
    "    * F1: 92.117 \n",
    "    * Recall: 92.931\n",
    "    * Precision: 91.318 \n",
    "    \n",
    "- Scores on Test Set:\n",
    "    * F1: 87.480\n",
    "    * Recall: 88.456\n",
    "    * Precision: 86.525\n",
    "    \n",
    "_Q. BiLSTM with Glove Embeddings outperforms the model without. Can you provide the rationale for this?_\n",
    "A. When using glove embeddings, our model has access to word vectors of length 100. This provides additional semantic information that can be useful for training the model. Further, there are 6B tokens in Glove embeddings, which can help cover several OOV tokens.\n",
    "\n",
    "#### Task 3:\n",
    "Hyperparameters used for creating and training Transformer Encoder without glove embeddings:\n",
    "\n",
    "* Model Architecture\n",
    "    - emb_dim = 128\n",
    "    - num_attention_heads = 8\n",
    "    - max_seq_len = 128\n",
    "    - ff_dim = 128\n",
    "    - input_dim = torch.max(train_data1) + 1\n",
    "    - out_dim = 9\n",
    "    - num_layers = 1 (unspecified in pdf)\n",
    "\n",
    "* Batch size = 32\n",
    "* Optimizer = AdamW\n",
    "* Learning rate = 2e-4\n",
    "* Loss function = Cross Entropy\n",
    "* epochs = 15\n",
    "\n",
    "- Scores on Validation Set:\n",
    "    * F1: 61.434\n",
    "    * Recall: 50.614\n",
    "    * Precision: 78.138\n",
    "    \n",
    "- Scores on Test Set:\n",
    "    * F1: 53.353\n",
    "    * Recall: 42.683\n",
    "    * Precision: 71.135\n",
    "    \n",
    "_Q. What is the reason behind the poor performance of the transformer_\n",
    "\n",
    "The size of the dataset maybe one of the constraints. \n",
    "Further, the model maybe too complex for the given task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc368d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhavi\\PycharmProjects\\DeepfakeDetectionUsingSWIN\\venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "from conlleval import evaluate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import copy\n",
    "import gzip\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5c89d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_true_and_pred(outputs, labels):\n",
    "    trues = labels.reshape(-1).cpu().numpy()\n",
    "    _, predicted = torch.max(outputs, 2)\n",
    "    preds = predicted.reshape(-1).cpu().numpy()\n",
    "    \n",
    "    combined = list(zip(trues, preds))\n",
    "    filtered = [(t, p) for (t, p) in combined if t != 9]\n",
    "    \n",
    "    trues, preds = zip(*filtered)\n",
    "    \n",
    "    return trues, preds\n",
    "\n",
    "def create_padded_sequences(seq_list, pad_list):\n",
    "    padded_seq = []\n",
    "    for sequence, pad_val in zip(seq_list, pad_list):\n",
    "        padded_seq.append(pad_sequence([torch.tensor(seq) for seq in sequence], batch_first=True, padding_value=pad_val))\n",
    "                          \n",
    "    return padded_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75ff55",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe42905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset conll2003 (C:/Users/bhavi/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 177.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset('conll2003')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90073a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-94f685dd779131c7.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-06709f5f03722b79.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-af9b1c2d3213b131.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'labels'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'labels'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'labels'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "new_dataset = dataset.map(lambda sample: {'labels': sample['ner_tags']}, remove_columns=['id', 'ner_tags', 'pos_tags', 'chunk_tags'])\n",
    "\n",
    "print(new_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fec24ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8, 'PAD-': 9}\n",
      "10 8128\n"
     ]
    }
   ],
   "source": [
    "word_freq = Counter(itertools.chain(*new_dataset['train']['tokens']))\n",
    "\n",
    "word2idx = {word: idx for idx, (word, freq) in enumerate(word_freq.items(), start=2) if freq >= 3}\n",
    "\n",
    "word2idx['[PAD]'] = 0\n",
    "word2idx['[UNK]'] = 1\n",
    "\n",
    "label2idx = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8, 'PAD-': 9}\n",
    "\n",
    "print(label2idx)\n",
    "\n",
    "print(len(label2idx), len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2b1873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-4f7e1dc6991de514.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-4e901fb40474f8cd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-ecdc3baa360136b6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['labels', 'input_ids'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['labels', 'input_ids'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['labels', 'input_ids'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "new_dataset1 = new_dataset.map(\n",
    "    lambda x: {\n",
    "        'input_ids': [word2idx.get(word, word2idx['[UNK]']) for word in x['tokens']],\n",
    "              },\n",
    "    remove_columns='tokens'\n",
    ")\n",
    "\n",
    "print(new_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc34b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_list = (word2idx['[PAD]'], label2idx['PAD-'])\n",
    "\n",
    "train_seq_list = (new_dataset1['train']['input_ids'], new_dataset1['train']['labels'])                     \n",
    "train_data1, train_labels1 = create_padded_sequences(train_seq_list, pad_list)\n",
    "\n",
    "val_seq_list = (new_dataset1['validation']['input_ids'], new_dataset1['validation']['labels'])\n",
    "val_data1, val_labels1 = create_padded_sequences(val_seq_list, pad_list)\n",
    "\n",
    "test_seq_list = (new_dataset1['test']['input_ids'], new_dataset1['test']['labels'])\n",
    "test_data1, test_labels1 = create_padded_sequences(test_seq_list, pad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa43ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sz = 32\n",
    "\n",
    "train_loader1 = DataLoader(\n",
    "    TensorDataset(train_data1, train_labels1),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader1 = DataLoader(\n",
    "    TensorDataset(val_data1, val_labels1),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader1 = DataLoader(\n",
    "    TensorDataset(test_data1, test_labels1),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb6c0afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23589) 9\n"
     ]
    }
   ],
   "source": [
    "input_dim = torch.max(train_data1) + 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_prob=0.33\n",
    "linear_dim=128\n",
    "\n",
    "\n",
    "out_dim = 9\n",
    "print(input_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3f2d5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from conlleval import evaluate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "import copy\n",
    "import gzip\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from utils import generate_true_and_pred, create_padded_sequences\n",
    "from models import *\n",
    "\n",
    "def task1_test(model, data_loader, device='cpu', verbose=False):\n",
    "    label2idx = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7,\n",
    "                 'I-MISC': 8, 'PAD-': 9}\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_true, all_pred = [], []\n",
    "\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            trues, preds = generate_true_and_pred(outputs, labels)\n",
    "            all_true.extend(trues)\n",
    "            all_pred.extend(preds)\n",
    "\n",
    "        label_map = {label: sym for sym, label in label2idx.items()}\n",
    "        all_true = [label_map[true] for true in all_true]\n",
    "        all_pred = [label_map[pred] for pred in all_pred]\n",
    "\n",
    "        res = evaluate(all_true, all_pred, verbose=verbose)\n",
    "        return res\n",
    "\n",
    "    \n",
    "def task1_train(model, train_loader, val_loader, optimizer, criterion, out_dim=9, num_epochs=10, patience=5, device='cpu', path='./task1-bilstm.pth'):\n",
    "    curr_patience = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_f1 = 0\n",
    "    \n",
    "    model = model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs.view(-1, out_dim), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        prec, rec, f1 = task1_test(model, val_loader, device=device)\n",
    "        print(f'Epoch: {epoch+1} / {num_epochs}, val_f1: {f1}, val_precision: {prec}, val_recall: {rec}')\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            curr_patience=0\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            curr_patience += 1\n",
    "\n",
    "        if curr_patience >= patience:\n",
    "            print(f'Stopping after {epoch+1} epochs')\n",
    "            torch.save(best_model.state_dict(), path)\n",
    "            return best_model\n",
    "\n",
    "    torch.save(best_model.state_dict(), path)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "01f1d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM1(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob):\n",
    "        super(BiLSTM1, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(num_embeddings=input_dim, embedding_dim=embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.drop = nn.Dropout(p=dropout_prob)\n",
    "        self.linear = nn.Linear(2 * hidden_dim, linear_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.out = nn.Linear(linear_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(torch.max(x))\n",
    "        out = self.emb(x)\n",
    "        # print(out.shape)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.elu(out)\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cd2e4f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8e7b9c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BiLSTM1(input_dim, embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob)\n",
    "model1.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label2idx['PAD-'])\n",
    "optimizer = optim.AdamW(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "75ecfddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20, val_f1: 57.556895545613685, val_precision: 68.17972350230414, val_recall: 49.798047795355096\n",
      "Epoch: 2 / 20, val_f1: 70.86255259467042, val_precision: 73.94804244420051, val_recall: 68.02423426455739\n",
      "Epoch: 3 / 20, val_f1: 72.56063691908905, val_precision: 80.63786008230453, val_recall: 65.95422416694716\n",
      "Epoch: 4 / 20, val_f1: 75.6775478396398, val_precision: 77.93829142143748, val_recall: 73.54426119151802\n",
      "Epoch: 5 / 20, val_f1: 77.5795732773697, val_precision: 80.74262832180561, val_recall: 74.65499831706495\n",
      "Epoch: 6 / 20, val_f1: 77.8346994535519, val_precision: 78.99480069324089, val_recall: 76.70817906428812\n",
      "Epoch: 7 / 20, val_f1: 78.17170663885992, val_precision: 80.81207330219188, val_recall: 75.69841804106362\n",
      "Epoch: 8 / 20, val_f1: 77.7972027972028, val_precision: 80.93852309930884, val_recall: 74.89060922248402\n",
      "Epoch: 9 / 20, val_f1: 77.9982891360137, val_precision: 79.31454418928323, val_recall: 76.72500841467519\n",
      "Epoch: 10 / 20, val_f1: 78.24516129032259, val_precision: 80.02815414393805, val_recall: 76.53988556041736\n",
      "Epoch: 11 / 20, val_f1: 77.33696577558318, val_precision: 78.25637491385251, val_recall: 76.43890945809491\n",
      "Epoch: 12 / 20, val_f1: 77.70415626882368, val_precision: 79.50343370311674, val_recall: 75.9845169976439\n",
      "Epoch: 13 / 20, val_f1: 78.45931958937813, val_precision: 79.1103507271172, val_recall: 77.81891618983508\n",
      "Epoch: 14 / 20, val_f1: 78.18303496737494, val_precision: 77.72787757817699, val_recall: 78.64355435880175\n",
      "Epoch: 15 / 20, val_f1: 79.16560238399319, val_precision: 80.11373427537481, val_recall: 78.23964994951194\n",
      "Epoch: 16 / 20, val_f1: 77.77777777777779, val_precision: 79.65772759350742, val_recall: 75.9845169976439\n",
      "Epoch: 17 / 20, val_f1: 79.24528301886792, val_precision: 80.41933806965864, val_recall: 78.10501514641534\n",
      "Epoch: 18 / 20, val_f1: 79.98602864128537, val_precision: 83.12159709618875, val_recall: 77.07842477280377\n",
      "Epoch: 19 / 20, val_f1: 79.66130983238293, val_precision: 81.85369318181817, val_recall: 77.58330528441603\n",
      "Epoch: 20 / 20, val_f1: 78.94464562855667, val_precision: 80.94059405940595, val_recall: 77.04476607202963\n"
     ]
    }
   ],
   "source": [
    "best_bilstm = task1_train(model1, train_loader1, val_loader1, optimizer, criterion, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e85b3449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 5510 phrases; correct: 4580.\n",
      "accuracy:  79.29%; (non-O)\n",
      "accuracy:  96.00%; precision:  83.12%; recall:  77.08%; FB1:  79.99\n",
      "              LOC: precision:  87.67%; recall:  84.76%; FB1:  86.19  1776\n",
      "             MISC: precision:  85.75%; recall:  73.75%; FB1:  79.30  793\n",
      "              ORG: precision:  74.84%; recall:  70.77%; FB1:  72.75  1268\n",
      "              PER: precision:  83.32%; recall:  75.68%; FB1:  79.32  1673\n",
      "F1:  79.98602864128537 Recall: 77.07842477280377 Precision: 83.12159709618875\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task1_test(best_bilstm, val_loader1, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f071c7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 5648 phrases; found: 5023 phrases; correct: 3764.\n",
      "accuracy:  71.03%; (non-O)\n",
      "accuracy:  93.80%; precision:  74.94%; recall:  66.64%; FB1:  70.55\n",
      "              LOC: precision:  80.74%; recall:  76.92%; FB1:  78.78  1589\n",
      "             MISC: precision:  72.40%; recall:  60.54%; FB1:  65.94  587\n",
      "              ORG: precision:  70.87%; recall:  61.95%; FB1:  66.11  1452\n",
      "              PER: precision:  73.62%; recall:  63.51%; FB1:  68.19  1395\n",
      "F1:  70.5463405491519 Recall: 66.643059490085 Precision: 74.93529763089786\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task1_test(best_bilstm, test_loader1, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4999afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_bilstm.state_dict(), './task1-bilstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b0d70949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 23589\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_prob = 0.33\n",
    "linear_dim = 128\n",
    "out_dim = 9\n",
    "\n",
    "model = BiLSTM1(input_dim, embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob)\n",
    "model.load_state_dict(torch.load('./task1-bilstm.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6fef93a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 5648 phrases; found: 5023 phrases; correct: 3764.\n",
      "accuracy:  71.03%; (non-O)\n",
      "accuracy:  93.80%; precision:  74.94%; recall:  66.64%; FB1:  70.55\n",
      "              LOC: precision:  80.74%; recall:  76.92%; FB1:  78.78  1589\n",
      "             MISC: precision:  72.40%; recall:  60.54%; FB1:  65.94  587\n",
      "              ORG: precision:  70.87%; recall:  61.95%; FB1:  66.11  1452\n",
      "              PER: precision:  73.62%; recall:  63.51%; FB1:  68.19  1395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74.93529763089786, 66.643059490085, 70.5463405491519)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "test(model, test_loader1, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf845d",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e0d3998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the glove embeddings and creating the vocabulary and embeddings with corresponding indices\n",
    "\n",
    "vocab, embeddings = [], []\n",
    "with gzip.open('glove.6B.100d.gz', 'rt', encoding='utf-8') as f:\n",
    "    full_content = f.read().strip().split('\\n')\n",
    "    \n",
    "for i in range(len(full_content)):\n",
    "    word = full_content[i].split(' ')[0]\n",
    "    emb = [float(val) for val in full_content[i].split(' ')[1:]]\n",
    "    vocab.append(word)\n",
    "    embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f985c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to np arrays\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9e7b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>' '<unk>' 'the' ',' '.' 'of' 'to' 'and' 'in' 'a']\n",
      "(400002, 100) (400002,)\n"
     ]
    }
   ],
   "source": [
    "# adding extra tokens for padding and oov words\n",
    "\n",
    "vocab_npa = np.insert(vocab_npa, 0, '<pad>')\n",
    "vocab_npa = np.insert(vocab_npa, 1, '<unk>')\n",
    "\n",
    "print(vocab_npa[:10])\n",
    "\n",
    "# adding the corresponding vectors for padding and oov words\n",
    "pad_emb = np.zeros((1, embs_npa.shape[1]))\n",
    "unk_emb = np.mean(embs_npa, axis=0, keepdims=True)\n",
    "\n",
    "# creating one emb_matrix by stacking the emb array on top of padding and oov words vectors\n",
    "embs_npa = np.vstack((pad_emb, unk_emb, embs_npa))\n",
    "print(embs_npa.shape, vocab_npa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e8225a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "np.save('./embs_npa.npy', embs_npa)\n",
    "np.save('./vocab_npa.npy', vocab_npa)\n",
    "\n",
    "vocab_npa2 = np.load('./vocab_npa.npy')\n",
    "embs_npa2 = np.load('./embs_npa.npy')\n",
    "\n",
    "print(all(vocab_npa2 == vocab_npa))\n",
    "print((embs_npa2 == embs_npa).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0dd8cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<unk>', 'the', ',', '.', 'of', 'to', 'and', 'in', 'a']\n"
     ]
    }
   ],
   "source": [
    "# a index mapper to obtain the index of the word in vocabulary. \n",
    "# This index also matches the index of the word vector in emb_matrix\n",
    "\n",
    "vocab2idx = {word: idx for idx, word in enumerate(vocab_npa)}\n",
    "print(list(vocab2idx.keys())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e138022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-77eba482711324ec.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-9212aab32977d975.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-5130e450f4d01990.arrow\n"
     ]
    }
   ],
   "source": [
    "# creating a variable which tells if there is a presence of an upper-case letter in a given token\n",
    "\n",
    "new_dataset2 = new_dataset.map(\n",
    "    lambda x: {        \n",
    "        'isCap': [int(token[0].isupper()) for token in x['tokens']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bb66d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'labels', 'isCap'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'labels', 'isCap'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'labels', 'isCap'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(new_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eb12a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('EU', 1), ('rejects', 0), ('German', 1), ('call', 0), ('to', 0), ('boycott', 0), ('British', 1), ('lamb', 0), ('.', 0))\n"
     ]
    }
   ],
   "source": [
    "print(tuple(zip(new_dataset2['train']['tokens'][0], new_dataset2['train']['isCap'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acc56364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-a8d2bcb8163fc566.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-9ee5d67b68aa1b11.arrow\n",
      "Loading cached processed dataset at C:\\Users\\bhavi\\.cache\\huggingface\\datasets\\conll2003\\conll2003\\1.0.0\\9a4d16a94f8674ba3466315300359b0acd891b68b6c8743ddf60b9c702adce98\\cache-9f5ef3480b4208da.arrow\n"
     ]
    }
   ],
   "source": [
    "# using the vocab2idx dictionary to obtain the index of a word (in its lowercase form) in the emb_matrix\n",
    "\n",
    "new_dataset2 = new_dataset2.map(\n",
    "    lambda x: {\n",
    "        'input_ids': [vocab2idx.get(token.lower(), vocab2idx['<unk>']) for token in x['tokens']]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7410147",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_list = (vocab2idx['<pad>'], label2idx['PAD-'], 0)\n",
    "\n",
    "train_seq_list = (new_dataset2['train']['input_ids'], new_dataset2['train']['labels'], new_dataset2['train']['isCap'])                     \n",
    "train_data2, train_labels2, train_caps = create_padded_sequences(train_seq_list, pad_list)\n",
    "\n",
    "val_seq_list = (new_dataset2['validation']['input_ids'], new_dataset2['validation']['labels'], new_dataset2['validation']['isCap'])\n",
    "val_data2, val_labels2, val_caps = create_padded_sequences(val_seq_list, pad_list)\n",
    "\n",
    "test_seq_list = (new_dataset2['test']['input_ids'], new_dataset2['test']['labels'], new_dataset2['test']['isCap'])\n",
    "test_data2, test_labels2, test_caps = create_padded_sequences(test_seq_list, pad_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b45f8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sz = 32\n",
    "\n",
    "train_loader2 = DataLoader(\n",
    "    TensorDataset(train_data2, train_caps, train_labels2),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader2 = DataLoader(\n",
    "    TensorDataset(val_data2, val_caps, val_labels2),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader2 = DataLoader(\n",
    "    TensorDataset(test_data2, test_caps, test_labels2),\n",
    "    batch_size=b_sz,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f31b035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the model architecture's variables\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_prob=0.33\n",
    "linear_dim=128\n",
    "\n",
    "out_dim = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "50ccc816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2_test(model, data_loader, device='cpu', verbose=False):\n",
    "    label2idx = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7,\n",
    "                 'I-MISC': 8, 'PAD-': 9}\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_true, all_pred = [], []\n",
    "\n",
    "        for inputs, caps, labels in data_loader:\n",
    "            inputs, caps, labels = inputs.to(device), caps.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs, caps)\n",
    "\n",
    "            trues = labels.view(-1).cpu().numpy()\n",
    "            _, predicted = torch.max(outputs, 2)\n",
    "            preds = predicted.view(-1).cpu().numpy()\n",
    "\n",
    "            for true, pred in zip(trues, preds):\n",
    "                if true != label2idx['PAD-']:\n",
    "                    all_true.append(true)\n",
    "                    all_pred.append(pred)\n",
    "\n",
    "        label_map = {label: sym for sym, label in label2idx.items()}\n",
    "        all_true = [label_map[true] for true in all_true]\n",
    "        all_pred = [label_map[pred] for pred in all_pred]\n",
    "\n",
    "        res = evaluate(all_true, all_pred, verbose=verbose)\n",
    "        return res\n",
    "\n",
    "\n",
    "def task2_train(model, train_loader, val_loader, optimizer, criterion, out_dim=9, num_epochs=10, patience=5, device='cpu', path='./task2-bilstm.pth'):\n",
    "    model = model.to(device)\n",
    "    curr_patience = 0\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for inputs, caps, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, caps, labels = inputs.to(device), caps.to(device), labels.to(device)\n",
    "            outputs = model(inputs, caps)\n",
    "\n",
    "            loss = criterion(outputs.view(-1, out_dim), labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        prec, rec, f1 = task2_test(model, val_loader, device=device)\n",
    "        print(f'Epoch: {epoch+1} / {num_epochs}, val_f1: {f1}, val_precision: {prec}, val_recall: {rec}')\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            curr_patience=0\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            curr_patience += 1\n",
    "\n",
    "        if curr_patience >= patience:\n",
    "            print(f'Stopping after {epoch+1} epochs')\n",
    "            torch.save(best_model.state_dict(), path)\n",
    "            return best_model\n",
    "\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "025f88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM2(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob, embs_npa):\n",
    "        super(BiLSTM2, self).__init__()\n",
    "        # loading the embedding from pretrained glove model stored in emb_matrix\n",
    "        self.emb = nn.Embedding.from_pretrained(torch.from_numpy(embs_npa2).float())\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim+1, hidden_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=dropout_prob)\n",
    "        \n",
    "        self.linear = nn.Linear(2 * hidden_dim, linear_dim)\n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "        self.clf = nn.Linear(linear_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x, caps):\n",
    "        out = self.emb(x)\n",
    "        \n",
    "        caps = caps.unsqueeze(2)\n",
    "        out = torch.cat([out, caps], dim=2)\n",
    "        \n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.elu(out)\n",
    "        out = self.clf(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "69e65c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "device = 'cuda:0'\n",
    "model2 = BiLSTM2(embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob, embs_npa)\n",
    "model2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label2idx['PAD-'])\n",
    "optimizer = optim.AdamW(model2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a142457f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 20, val_f1: 84.63509380940573, val_precision: 83.15738184180607, val_recall: 86.1662739818243\n",
      "Epoch: 2 / 20, val_f1: 86.6339515927805, val_precision: 85.64380858411445, val_recall: 87.6472568158869\n",
      "Epoch: 3 / 20, val_f1: 90.07328447701532, val_precision: 89.15265413781735, val_recall: 91.01312689330192\n",
      "Epoch: 4 / 20, val_f1: 90.57482738540887, val_precision: 89.55420299391346, val_recall: 91.61898350723662\n",
      "Epoch: 5 / 20, val_f1: 90.68426769153646, val_precision: 90.04479840716775, val_recall: 91.33288455065635\n",
      "Epoch: 6 / 20, val_f1: 91.44385026737967, val_precision: 90.80650514437438, val_recall: 92.09020531807472\n",
      "Epoch: 7 / 20, val_f1: 91.11969111969111, val_precision: 90.89082384460816, val_recall: 91.34971390104342\n",
      "Epoch: 8 / 20, val_f1: 91.66805810652865, val_precision: 90.95427435387674, val_recall: 92.39313362504208\n",
      "Epoch: 9 / 20, val_f1: 91.23651452282158, val_precision: 89.99672560576293, val_recall: 92.5109390777516\n",
      "Epoch: 10 / 20, val_f1: 91.61806365605733, val_precision: 90.72607260726072, val_recall: 92.52776842813869\n",
      "Epoch: 11 / 20, val_f1: 91.19015957446808, val_precision: 90.08210180623973, val_recall: 92.32581622349377\n",
      "Epoch: 12 / 20, val_f1: 91.2747216220708, val_precision: 90.15101772816809, val_recall: 92.42679232581622\n",
      "Epoch: 13 / 20, val_f1: 91.7056074766355, val_precision: 90.94670638861304, val_recall: 92.47728037697745\n",
      "Epoch: 14 / 20, val_f1: 91.76195643101578, val_precision: 91.02500413975824, val_recall: 92.5109390777516\n",
      "Epoch: 15 / 20, val_f1: 91.466156023645, val_precision: 90.50914483440435, val_recall: 92.4436216762033\n",
      "Epoch: 16 / 20, val_f1: 92.11777462674118, val_precision: 91.31800893004795, val_recall: 92.93167283742848\n",
      "Epoch: 17 / 20, val_f1: 91.83503088996493, val_precision: 91.11994698475812, val_recall: 92.56142712891283\n",
      "Epoch: 18 / 20, val_f1: 91.60279906697767, val_precision: 90.6961398878258, val_recall: 92.52776842813869\n",
      "Epoch: 19 / 20, val_f1: 91.81696726786907, val_precision: 91.11700364600597, val_recall: 92.52776842813869\n",
      "Epoch: 20 / 20, val_f1: 91.35040453749271, val_precision: 90.55730114106169, val_recall: 92.15752271962302\n"
     ]
    }
   ],
   "source": [
    "best_bilstm = task2_train(model2, train_loader2, val_loader2, optimizer, criterion, num_epochs=20, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7b9a0e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 5942 phrases; found: 6047 phrases; correct: 5522.\n",
      "accuracy:  93.00%; (non-O)\n",
      "accuracy:  98.61%; precision:  91.32%; recall:  92.93%; FB1:  92.12\n",
      "              LOC: precision:  93.91%; recall:  96.57%; FB1:  95.22  1889\n",
      "             MISC: precision:  83.28%; recall:  86.98%; FB1:  85.09  963\n",
      "              ORG: precision:  88.45%; recall:  86.80%; FB1:  87.62  1316\n",
      "              PER: precision:  94.84%; recall:  96.74%; FB1:  95.78  1879\n",
      "F1:  92.11777462674118 Recall: 92.93167283742848 Precision: 91.31800893004795\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task2_test(best_bilstm, val_loader2, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "77a6218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 5648 phrases; found: 5774 phrases; correct: 4996.\n",
      "accuracy:  89.88%; (non-O)\n",
      "accuracy:  97.62%; precision:  86.53%; recall:  88.46%; FB1:  87.48\n",
      "              LOC: precision:  88.20%; recall:  92.33%; FB1:  90.22  1746\n",
      "             MISC: precision:  70.77%; recall:  78.63%; FB1:  74.49  780\n",
      "              ORG: precision:  84.67%; recall:  83.44%; FB1:  84.05  1637\n",
      "              PER: precision:  94.23%; recall:  93.88%; FB1:  94.05  1611\n",
      "F1:  87.48030117317457 Recall: 88.45609065155807 Precision: 86.52580533425702\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task2_test(best_bilstm, test_loader2, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eabaa680",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_bilstm.state_dict(), './task2-bilstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ac1bce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_prob = 0.33\n",
    "linear_dim = 128\n",
    "out_dim = 9\n",
    "\n",
    "model = BiLSTM2(embedding_dim, hidden_dim, linear_dim, out_dim, dropout_prob, embs_npa)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./task2-bilstm.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e012fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, f1 = test(model, test_loader2, isCaps=True, device=device, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6363dd1",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "134ac816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        den = torch.exp(-torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
    "        pos = torch.arange(0, max_len).reshape(max_len, 1)\n",
    "        pos_embedding = torch.zeros((max_len, d_model))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        \n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "598d798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "    \n",
    "        self.emb = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.emb_size = embedding_dim\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        return self.emb(tokens.long()) * math.sqrt(self.emb_size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6eca50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, num_attention_heads, ff_dim, max_seq_len, out_dim):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "        \n",
    "        self.src_token_emb = TokenEmbedding(input_dim, embedding_dim)\n",
    "        \n",
    "        self.pos_enc = PositionalEncoding(embedding_dim, max_seq_len)\n",
    "        \n",
    "        self.enc_layer = nn.TransformerEncoderLayer(d_model=embedding_dim, nhead=num_attention_heads, dim_feedforward=ff_dim)\n",
    "        self.encoder = nn.TransformerEncoder(self.enc_layer, num_layers=1)\n",
    "        \n",
    "        self.clf = nn.Linear(embedding_dim, out_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask=None, src_key_padding_mask=None):\n",
    "        out = self.src_token_emb(x)\n",
    "        # print('Shape after passing in token embeddings:', out.size())\n",
    "        \n",
    "        out = self.pos_enc(out)\n",
    "        # print('Shape after passing through source embeddings:', out.size())\n",
    "        \n",
    "        out = self.encoder(out, mask=mask, src_key_padding_mask=src_key_padding_mask)\n",
    "        # print('After passing through the transformer encoder:', out.size())\n",
    "        \n",
    "        out = self.clf(out)\n",
    "        # print('Final output shape before reshaping:', out.size())\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d599ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task3_test(model, data_loader, device='cpu', verbose=False):\n",
    "    label2idx = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7,\n",
    "                 'I-MISC': 8, 'PAD-': 9}\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_true, all_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data, labels = data.transpose(0, 1).to(device), labels.transpose(0, 1).to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            trues, preds = generate_true_and_pred(outputs, labels)\n",
    "\n",
    "            all_true.extend(trues)\n",
    "            all_pred.extend(preds)\n",
    "\n",
    "    label_map = {label: sym for sym, label in label2idx.items()}\n",
    "    all_true = [label_map[true] for true in all_true]\n",
    "    all_pred = [label_map[pred] for pred in all_pred]\n",
    "\n",
    "    res = evaluate(all_true, all_pred, verbose=verbose)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def task3_train(model, train_loader, val_loader, criterion, optimizer, num_epochs=5, device='cpu', verbose=False):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.transpose(0, 1).to(device), labels.transpose(0, 1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            src_mask = torch.zeros((data.size(0), data.size(0)), device=device)\n",
    "            src_pad_mask = (data == word2idx['[PAD]']).transpose(0, 1)\n",
    "\n",
    "            outputs = model(data, src_key_padding_mask=src_pad_mask)\n",
    "            outputs = outputs.reshape(-1, out_dim)\n",
    "            labels = labels.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        all_true, all_pred = [], []\n",
    "        for data, labels in val_loader:\n",
    "            data, labels = data.transpose(0, 1).to(device), labels.transpose(0, 1).to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            trues, preds = generate_true_and_pred(outputs, labels)\n",
    "            all_true.extend(trues)\n",
    "            all_pred.extend(preds)\n",
    "\n",
    "        label_map = {label: sym for sym, label in label2idx.items()}\n",
    "        all_true = [label_map[true] for true in all_true]\n",
    "        all_pred = [label_map[pred] for pred in all_pred]\n",
    "\n",
    "        prec, rec, f1 = evaluate(all_true, all_pred, verbose=verbose)\n",
    "        print(f'Epoch: {epoch + 1} / {num_epochs}, val_f1: {f1}, val_precision: {prec}, val_recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbcb1801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(23589) 9\n"
     ]
    }
   ],
   "source": [
    "emb_dim = 128\n",
    "num_attention_heads = 8\n",
    "max_seq_len = 128\n",
    "ff_dim = 128\n",
    "\n",
    "input_dim = torch.max(train_data1) + 1\n",
    "out_dim = 9\n",
    "\n",
    "print(input_dim, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "023cc38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# input_dim, embedding_dim, num_attention_heads, ff_dim, max_seq_len, out_dim\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "# device='cpu'\n",
    "model3 = TransformerEncoderModel(input_dim, emb_dim, num_attention_heads, ff_dim, max_seq_len, out_dim)\n",
    "model3 = model3.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=label2idx['PAD-'])\n",
    "optimizer = optim.Adam(model3.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5dbdb121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 15, val_f1: 5.50500978924335, val_precision: 80.47138047138047, val_recall: 2.8499880753637017\n",
      "Epoch: 2 / 15, val_f1: 18.193185370428257, val_precision: 70.8603896103896, val_recall: 10.436341900777048\n",
      "Epoch: 3 / 15, val_f1: 25.908649173955293, val_precision: 69.93704092339979, val_recall: 15.899332061068701\n",
      "Epoch: 4 / 15, val_f1: 35.183666028620905, val_precision: 74.57496136012365, val_recall: 23.022784206131455\n",
      "Epoch: 5 / 15, val_f1: 41.02256155099939, val_precision: 73.36606320957348, val_recall: 28.471064539175995\n",
      "Epoch: 6 / 15, val_f1: 46.021575148024986, val_precision: 71.67761495704902, val_recall: 33.8908135228766\n",
      "Epoch: 7 / 15, val_f1: 50.610739801797635, val_precision: 71.34502923976608, val_recall: 39.214285714285715\n",
      "Epoch: 8 / 15, val_f1: 52.23038268264399, val_precision: 74.32343234323432, val_recall: 40.26221692491061\n",
      "Epoch: 9 / 15, val_f1: 55.278538137160616, val_precision: 72.72727272727273, val_recall: 44.582338902147974\n",
      "Epoch: 10 / 15, val_f1: 56.857891671520086, val_precision: 73.04526748971193, val_recall: 46.5435041716329\n",
      "Epoch: 11 / 15, val_f1: 57.51846381093058, val_precision: 75.43587756683456, val_recall: 46.478873239436616\n",
      "Epoch: 12 / 15, val_f1: 57.08034703885326, val_precision: 77.52049180327869, val_recall: 45.170149253731346\n",
      "Epoch: 13 / 15, val_f1: 59.629142940575264, val_precision: 76.69483568075117, val_recall: 48.775827063179264\n",
      "Epoch: 14 / 15, val_f1: 61.758336942399296, val_precision: 78.1227173119065, val_recall: 51.06230603962759\n",
      "Epoch: 15 / 15, val_f1: 61.61645422943221, val_precision: 78.35697181801436, val_recall: 50.76978159684926\n"
     ]
    }
   ],
   "source": [
    "task3_train(model3, train_loader1, val_loader1, criterion, optimizer, num_epochs=15, device=device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f86e44c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 51362 tokens with 8375 phrases; found: 5425 phrases; correct: 4239.\n",
      "accuracy:  45.51%; (non-O)\n",
      "accuracy:  90.37%; precision:  78.14%; recall:  50.61%; FB1:  61.43\n",
      "              LOC: precision:  82.30%; recall:  65.88%; FB1:  73.18  1661\n",
      "             MISC: precision:  87.63%; recall:  60.16%; FB1:  71.34  865\n",
      "              ORG: precision:  72.49%; recall:  41.41%; FB1:  52.71  1167\n",
      "              PER: precision:  73.21%; recall:  42.31%; FB1:  53.63  1732\n",
      "F1:  61.434782608695656 Recall: 50.61492537313433 Precision: 78.13824884792628\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task3_test(model3, val_loader1, device=device, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "84f88232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 46435 tokens with 7893 phrases; found: 4736 phrases; correct: 3369.\n",
      "accuracy:  37.87%; (non-O)\n",
      "accuracy:  88.17%; precision:  71.14%; recall:  42.68%; FB1:  53.35\n",
      "              LOC: precision:  81.75%; recall:  61.40%; FB1:  70.13  1436\n",
      "             MISC: precision:  71.58%; recall:  51.15%; FB1:  59.67  651\n",
      "              ORG: precision:  68.26%; recall:  34.05%; FB1:  45.43  1213\n",
      "              PER: precision:  62.74%; recall:  34.15%; FB1:  44.23  1436\n",
      "F1:  53.35339298440098 Recall: 42.68339034587609 Precision: 71.13597972972973\n"
     ]
    }
   ],
   "source": [
    "prec, rec, f1 = task3_test(model3, test_loader1, device=device, verbose=True)\n",
    "print('F1: ', f1, 'Recall:', rec, 'Precision:', prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3.state_dict(), './task3-optimus-prime.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b8d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
